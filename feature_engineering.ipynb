{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5klkVKdViL3"
      },
      "source": [
        "# Feature Engineering\n",
        "\n",
        "---\n",
        "\n",
        "1. Import packages\n",
        "2. Load data\n",
        "3. Feature engineering\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jTBFPsYViL5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yML3J2dBViL6"
      },
      "source": [
        "---\n",
        "## 2. Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gs_MlwWXViL7"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/client_data.csv')\n",
        "df[\"date_activ\"] = pd.to_datetime(df[\"date_activ\"], format='%Y-%m-%d')\n",
        "df[\"date_end\"] = pd.to_datetime(df[\"date_end\"], format='%Y-%m-%d')\n",
        "df[\"date_modif_prod\"] = pd.to_datetime(df[\"date_modif_prod\"], format='%Y-%m-%d')\n",
        "df[\"date_renewal\"] = pd.to_datetime(df[\"date_renewal\"], format='%Y-%m-%d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKlQLcShViL7"
      },
      "outputs": [],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czM1NLYBViL7"
      },
      "source": [
        "---\n",
        "\n",
        "## 3. Feature engineering\n",
        "\n",
        "### Difference between off-peak prices in December and preceding January\n",
        "\n",
        "Below is the code created by your colleague to calculate the feature described above. Use this code to re-create this feature and then think about ways to build on this feature to create features with a higher predictive power."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dp31WhzLViL8"
      },
      "outputs": [],
      "source": [
        "price_df = pd.read_csv('/content/price_data.csv')\n",
        "price_df[\"price_date\"] = pd.to_datetime(price_df[\"price_date\"], format='%Y-%m-%d')\n",
        "price_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyt4MaFEViL8"
      },
      "outputs": [],
      "source": [
        "# Group off-peak prices by companies and month\n",
        "monthly_price_by_id = price_df.groupby(['id', 'price_date']).agg({'price_off_peak_var': 'mean', 'price_off_peak_fix': 'mean'}).reset_index()\n",
        "\n",
        "# Get january and december prices\n",
        "jan_prices = monthly_price_by_id.groupby('id').first().reset_index()\n",
        "dec_prices = monthly_price_by_id.groupby('id').last().reset_index()\n",
        "\n",
        "# Calculate the difference\n",
        "diff = pd.merge(dec_prices.rename(columns={'price_off_peak_var': 'dec_1', 'price_off_peak_fix': 'dec_2'}), jan_prices.drop(columns='price_date'), on='id')\n",
        "diff['offpeak_diff_dec_january_energy'] = diff['dec_1'] - diff['price_off_peak_var']\n",
        "diff['offpeak_diff_dec_january_power'] = diff['dec_2'] - diff['price_off_peak_fix']\n",
        "diff = diff[['id', 'offpeak_diff_dec_january_energy','offpeak_diff_dec_january_power']]\n",
        "diff.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the original dataset\n",
        "df = pd.read_csv('/content/client_data.csv')\n",
        "\n",
        "# Perform data cleaning steps\n",
        "# Example cleaning steps:\n",
        "# 1. Handling missing values\n",
        "df = df.dropna()  # Remove rows with missing values\n",
        "\n",
        "# 2. Handling outliers\n",
        "# Apply appropriate outlier treatment techniques, such as capping/extending values or Winsorization\n",
        "\n",
        "# 3. Data type conversion\n",
        "date_columns = ['date_activ', 'date_end', 'date_modif_prod', 'date_renewal']\n",
        "for col in date_columns:\n",
        "    try:\n",
        "        df[col] = pd.to_datetime(df[col], format='%Y-%m-%d')\n",
        "    except ValueError:\n",
        "        print(f\"Error converting column '{col}' to datetime.\")\n",
        "\n",
        "# 4. Removing duplicates\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# 5. Fixing inconsistencies\n",
        "# Apply necessary corrections to handle inconsistencies in the data\n",
        "\n",
        "# 6. Feature scaling/normalization\n",
        "# Apply appropriate scaling or normalization techniques if required\n",
        "\n",
        "# 7. Handling skewed data\n",
        "# Apply appropriate transformations to handle skewed distributions\n",
        "\n",
        "# 8. Data integration\n",
        "# If applicable, integrate multiple datasets based on common variables or keys\n",
        "\n",
        "# 9. Handling irrelevant/redundant features\n",
        "# Remove irrelevant or redundant features that do not contribute much to the analysis\n",
        "\n",
        "# Save the cleaned data to a new CSV file\n",
        "df.to_csv('clean_data_after_eda.csv', index=False)\n"
      ],
      "metadata": {
        "id": "Q28bxykUVoGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Import packages\n",
        "# Already imported in the given code snippet\n",
        "\n",
        "# 2. Load data\n",
        "df = pd.read_csv('/content/clean_data_after_eda.csv')\n",
        "df[\"date_activ\"] = pd.to_datetime(df[\"date_activ\"], format='%Y-%m-%d')\n",
        "df[\"date_end\"] = pd.to_datetime(df[\"date_end\"], format='%Y-%m-%d')\n",
        "df[\"date_modif_prod\"] = pd.to_datetime(df[\"date_modif_prod\"], format='%Y-%m-%d')\n",
        "df[\"date_renewal\"] = pd.to_datetime(df[\"date_renewal\"], format='%Y-%m-%d')\n",
        "\n",
        "# 3. Feature engineering\n",
        "\n",
        "# 3.1 Difference between off-peak prices in December and preceding January\n",
        "\n",
        "# Load the price data\n",
        "price_df = pd.read_csv('/content/price_data.csv')\n",
        "price_df[\"price_date\"] = pd.to_datetime(price_df[\"price_date\"], format='%Y-%m-%d')\n",
        "\n",
        "# Group off-peak prices by companies and month\n",
        "monthly_price_by_id = price_df.groupby(['id', 'price_date']).agg({'price_off_peak_var': 'mean', 'price_off_peak_fix': 'mean'}).reset_index()\n",
        "\n",
        "# Get January and December prices\n",
        "jan_prices = monthly_price_by_id.groupby('id').first().reset_index()\n",
        "dec_prices = monthly_price_by_id.groupby('id').last().reset_index()\n",
        "\n",
        "# Calculate the difference\n",
        "diff = pd.merge(dec_prices.rename(columns={'price_off_peak_var': 'dec_1', 'price_off_peak_fix': 'dec_2'}), jan_prices.drop(columns='price_date'), on='id')\n",
        "diff['offpeak_diff_dec_january_energy'] = diff['dec_1'] - diff['price_off_peak_var']\n",
        "diff['offpeak_diff_dec_january_power'] = diff['dec_2'] - diff['price_off_peak_fix']\n",
        "diff = diff[['id', 'offpeak_diff_dec_january_energy', 'offpeak_diff_dec_january_power']]\n",
        "diff.head()\n"
      ],
      "metadata": {
        "id": "75h5ekFwVofn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KjWQgSV0eb6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# 1. Load data\n",
        "df = pd.read_csv('/content/clean_data_after_eda.csv')\n",
        "df[\"date_activ\"] = pd.to_datetime(df[\"date_activ\"], format='%Y-%m-%d')\n",
        "df[\"date_end\"] = pd.to_datetime(df[\"date_end\"], format='%Y-%m-%d')\n",
        "df[\"date_modif_prod\"] = pd.to_datetime(df[\"date_modif_prod\"], format='%Y-%m-%d')\n",
        "df[\"date_renewal\"] = pd.to_datetime(df[\"date_renewal\"], format='%Y-%m-%d')\n",
        "\n",
        "# 2. Feature engineering (including the additional feature created in Sub-Task 1)\n",
        "\n",
        "# Add the feature 'offpeak_diff_dec_january_energy' to the main dataframe\n",
        "df = pd.merge(df, diff[['id', 'offpeak_diff_dec_january_energy']], on='id', how='left')\n",
        "\n",
        "# Add other additional features based on the provided code and other feature engineering ideas\n",
        "\n",
        "# 3. Data Split\n",
        "X = df.drop('churn', axis=1)\n",
        "y = df['churn']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. Model Training\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# 5. Model Evaluation\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "y_pred_proba = rf_classifier.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"AUC-ROC:\", roc_auc_score(y_test, y_pred_proba))\n",
        "\n",
        "# Perform additional analysis and interpretation of the model's performance\n",
        "\n",
        "# Assess the advantages and disadvantages of using Random Forest for this use case\n",
        "\n",
        "# Tie business metrics to model performance by estimating potential savings\n",
        "# Conduct further analysis and simulations to estimate the financial impact of the model\n"
      ],
      "metadata": {
        "id": "dV6ykOkFeB5i"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "152bf6e7dc8ee53edb5af21dc1a8faeab7f134840808a94079ed98d91ece7e0c"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}